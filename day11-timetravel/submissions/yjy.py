import uuid
import json
from dotenv import load_dotenv
from typing_extensions import TypedDict

from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.sqlite import SqliteSaver
from langchain_google_genai import ChatGoogleGenerativeAI

load_dotenv()

# =========================================================
# ìƒíƒœ ì •ì˜
# =========================================================
class AegisState(TypedDict, total=False):
    frame_id: str
    frame_meta: str

    # --- VLM ê²°ê³¼ ---
    vlm_status: str      # ì •ìƒ/ì˜ì‹¬/ì´ìƒ
    vlm_class: str       # ì ˆë„/íŒŒì†/ì‹¤ì‹ /í­í–‰/íˆ¬ê¸°/none
    vlm_report: str

    # --- LLM ê²°ê³¼ ---
    final_label: str     # ì •ìƒ/ì´ìƒ

    # --- ì‹œìŠ¤í…œ ê²°ì • ---
    decision: str
    final_report: str


# =========================================================
# ëª¨ë¸
# =========================================================
model = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0
)


def safe_json(text: str):
    text = text.strip().replace("```json", "").replace("```", "")
    return json.loads(text)


# =========================================================
# ğŸ”µ ACTION TABLE (LLM ì˜ì¡´ ì œê±° â†’ ì•ˆì •ì„± â†‘)
# =========================================================
ACTION_MAP = {
    "ì‹¤ì‹ ": "119 ì‹ ê³ ",
    "í­í–‰": "ë³´ì•ˆíŒ€ ê¸´ê¸‰ ì¶œë™",
    "ì ˆë„": "ê²½ì°° ì‹ ê³ ",
    "íŒŒì†": "ì‹œì„¤ ê´€ë¦¬ì í˜¸ì¶œ",
    "íˆ¬ê¸°": "ê²½ê³  ë°©ì†¡ ë° ê¸°ë¡",
    "none": "ë¡œê·¸ ì €ì¥"
}


# =========================================================
# 1ï¸âƒ£ VLM : perception ONLY
# =========================================================
def vlm_perception(state: AegisState):
    print("ğŸ”µ [VLM] ì¸ì‹ ë‹¨ê³„")

    prompt = f"""
ê°ì²´ì™€ í–‰ë™ë§Œ ì‚¬ì‹¤ ê·¸ëŒ€ë¡œ ë¬˜ì‚¬í•˜ê³  íŒë‹¨í•˜ì§€ ë§ˆ.

JSON:
{{
 "status": "ì •ìƒ|ì˜ì‹¬|ì´ìƒ",
 "class": "ì ˆë„|íŒŒì†|ì‹¤ì‹ |í­í–‰|íˆ¬ê¸°|none",
 "report": "ì‚¬ì‹¤ ë¬˜ì‚¬ í•œ ë¬¸ì¥"
}}

ì¥ë©´: {state['frame_meta']}
"""

    data = safe_json(model.invoke(prompt).content)

    return {
        "vlm_status": data["status"],
        "vlm_class": data["class"],
        "vlm_report": data["report"]
    }


# =========================================================
# 2ï¸âƒ£ LLM : reasoning ONLY
# =========================================================
def llm_validation(state: AegisState):
    print("ğŸŸ£ [LLM] íŒë‹¨ ë‹¨ê³„")

    prompt = f"""
ë‹¤ìŒ ì •ë³´ë¥¼ ë³´ê³  ìµœì¢… ì´ìƒ ì—¬ë¶€ë§Œ íŒë‹¨í•˜ë¼.

status={state['vlm_status']}
class={state['vlm_class']}
report={state['vlm_report']}

JSON:
{{ "final_label": "ì •ìƒ|ì´ìƒ" }}
"""

    data = safe_json(model.invoke(prompt).content)

    return {"final_label": data["final_label"]}


# =========================================================
# 3ï¸âƒ£ ì‹œìŠ¤í…œ : deterministic action + ë³´ê³ ì„œ ìƒì„±
# =========================================================
def generate_report(state: AegisState):
    print("ğŸŸ¢ [SYSTEM] ì•¡ì…˜/ë³´ê³ ì„œ ìƒì„±")

    decision = ACTION_MAP.get(state["vlm_class"], "ë¡œê·¸ ì €ì¥")

    report = (
        f"[ë¼ë²¨:{state['final_label']} / ë¶„ë¥˜:{state['vlm_class']}]\n"
        f"ì–¸ì œ: ì‹¤ì‹œê°„ ê°ì§€\n"
        f"ì–´ë””ì„œ: ê³µì¥ CCTV\n"
        f"ë¬´ì—‡ì„: {state['vlm_report']}\n"
        f"ì™œ: ì´ìƒ í–‰ìœ„ ê°€ëŠ¥ì„± íƒì§€\n"
        f"ì–´ë–»ê²Œ: {decision}"
    )

    return {
        "decision": decision,
        "final_report": report
    }


# =========================================================
# Graph êµ¬ì„±
# =========================================================
builder = StateGraph(AegisState)

builder.add_node("vlm", vlm_perception)
builder.add_node("llm", llm_validation)
builder.add_node("report", generate_report)

builder.add_edge(START, "vlm")
builder.add_edge("vlm", "llm")
builder.add_edge("llm", "report")
builder.add_edge("report", END)


# =========================================================
# ğŸš€ ì‹¤í–‰ + Time Travel ë°ëª¨
# =========================================================
if __name__ == "__main__":

    config = {"configurable": {"thread_id": "aegis_demo"}}

    with SqliteSaver.from_conn_string("checkpoints.db") as saver:

        graph = builder.compile(checkpointer=saver)

        # =================================================
        # 1. ìµœì´ˆ ì‹¤í–‰
        # =================================================
        print("\n========== 1ï¸âƒ£ ìµœì´ˆ ì‹¤í–‰ ==========")

        result = graph.invoke({
            "frame_id": str(uuid.uuid4())[:8],
            "frame_meta": "ì•¼ê°„ ê³µì¥, ë‚¨ì„± í•œ ëª…ì´ ë°”ë‹¥ì— ì“°ëŸ¬ì ¸ ì›€ì§ì´ì§€ ì•ŠìŒ"
        }, config)

        print("\n[ì´ˆê¸° ê²°ê³¼]")
        print(json.dumps(result, indent=2, ensure_ascii=False))


        # =================================================
        # 2. ì²´í¬í¬ì¸íŠ¸ ì¡°íšŒ
        # =================================================
        print("\n========== 2ï¸âƒ£ íˆìŠ¤í† ë¦¬ ì¡°íšŒ ==========")

        states = list(graph.get_state_history(config))

        # ì•ˆì „í•œ íƒìƒ‰ (ë…¸ë“œ ê¸°ë°˜)
        target_state = next(s for s in states if s.next == ("llm",))

        print("ë³µì› ì‹œì :", target_state.next)


        # =================================================
        # 3. Time Travel (ì˜¤íƒ ìˆ˜ì •)
        # =================================================
        print("\n========== 3ï¸âƒ£ ê³¼ê±° ìˆ˜ì • ==========")

        new_config = graph.update_state(
            target_state.config,
            values={
                "vlm_status": "ì •ìƒ",
                "vlm_class": "none",
                "vlm_report": "ë‚¨ì„±ì´ íœ´ì‹ì„ ìœ„í•´ ì ì‹œ ë°”ë‹¥ì— ì•‰ì•„ ìˆìŒ"
            }
        )


        # =================================================
        # 4. ì¬ì‹¤í–‰
        # =================================================
        print("\n========== 4ï¸âƒ£ Fork ì¬ì‹¤í–‰ ==========")

        forked = graph.invoke(None, new_config)

        print("\n[ìˆ˜ì • í›„ ê²°ê³¼]")
        print(json.dumps(forked, indent=2, ensure_ascii=False))

