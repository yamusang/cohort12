# day1-localserver

## 오늘의 핵심
- langsmith를 이용하면 편하게 디버깅을 할 수 있다.
- langgraph dev를 이용하면 로컬 서버를 쉽게 실행할 수 있다.
- 오늘의 내용은 내가 만든 코드(에이전트)를 실행하고 결과를 쉽게 확인할 수 있도록 하는 것이었다.

## 회고 모음
- {{윤지연}}: 내가 어떤 모델을 쓰겠다고 코드를 작성했는지 다시 한 번 살펴보자. 
- {{선태영}}: 구글은 대인배다.
- {{홍자영}}: 순차적으로 설치를 잘 하고 넘어가기, 코드랑 env 파일 잘 비교해서 넣기
- {{김민서}}: 아침에 늦게 와서 수업 제대로 못 들었는데 pdf에 잘 써주셔서 감사합니다.
- {{이선영}}: lang smith를 통해 모니터링하며 결과를 확인할 수 있다. 
- {{홍선아}}: 랭체인
- {{배정윤}}: gemini로 바꾸면, LLM 모델 초기화시 model_provider 바꿔줘야하고, 호환성 문제는 error 메세지에 따라 잘 깔아보자.
- {{나이삭}}: 랭체인 어렵다요.
- {{임정수}}: API KEY 어디서 뽑는지 드디어 알았습니다.
- {{김동국}}: LangSmith 이용해서 굳이 print 하지 않아도 확인해 볼 수 있었다. 
- {{임은상}}: 로컬 서버로 API 형식으로 LangGraph 로컬 서버를 실행할 수 있음
- {{양승준}}: LangGraph 로컬 서버를 실행하고 OpenAI API를 연결하여 에이전트와 통신하는 구조를 이해했습니다.
- {{곽수영}}: 로컬 서버로 API 형식으로 LangGraph 로컬 서버를 실행할 수 있음

## 자주 나온 질문
- 각 파일의 위치가 헷갈린다.
- 어떤 상황에서 무슨 명령어를 써야 하는지 헷갈린다.
- 설정하는게 어려웠다.

