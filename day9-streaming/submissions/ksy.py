from dotenv import load_dotenv
load_dotenv()

# =========================================================
# 1. ê¸°ë³¸ ìŠ¤íŠ¸ë¦¬ë° (updates / values / custom / messages / debug)
# =========================================================

from typing import TypedDict, Annotated
from langchain_anthropic import ChatAnthropic
from langgraph.graph import StateGraph, START, END
from langgraph.config import get_stream_writer

# 1. ìƒíƒœ ì •ì˜
class ResearchState(TypedDict):
    query: str
    raw_data: str
    summary: str

# LLM ì„¤ì • (2026ë…„ ìµœì‹  ëª¨ë¸ ê¸°ì¤€)
llm = ChatAnthropic(model="claude-haiku-4-5-20251001")

# 2. ë…¸ë“œ ì •ì˜
def search_engine(state: ResearchState):
    writer = get_stream_writer()
    writer("ğŸŒ ì›¹ ë°ì´í„° ê²€ìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # ì‹¤ì œ ê²€ìƒ‰ ëŒ€ì‹  ì‹œë®¬ë ˆì´ì…˜
    search_result = f"'{state['query']}'ì— ëŒ€í•œ ìµœì‹  íŠ¸ë Œë“œëŠ” AI ì—ì´ì „íŠ¸ì˜ ììœ¨ì„± ê°•í™”ì…ë‹ˆë‹¤."
    
    writer("âœ… ê²€ìƒ‰ ì™„ë£Œ! ìš”ì•½ ë‹¨ê³„ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
    return {"raw_data": search_result}

def summarize_info(state: ResearchState):
    writer = get_stream_writer()
    writer("âœï¸ ìš”ì•½ë¬¸ ìƒì„± ì¤‘...")
    
    response = llm.invoke(f"ë‹¤ìŒ ë°ì´í„°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜: {state['raw_data']}")
    
    return {"summary": response.content}

# 3. ê·¸ë˜í”„ êµ¬ì„±
workflow = StateGraph(ResearchState)

workflow.add_node("search", search_engine)
workflow.add_node("summarize", summarize_info)

workflow.add_edge(START, "search")
workflow.add_edge("search", "summarize")
workflow.add_edge("summarize", END)

app = workflow.compile()

# 4. ë©€í‹° ëª¨ë“œ ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
print("=== ì‹¤ì‹œê°„ ë¦¬ì„œì¹˜ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ===\n")

inputs = {"query": "2026ë…„ AI íŠ¸ë Œë“œ"}

# ì£¼ë¡œ ì‹¤ë¬´ì—ì„œëŠ” 'custom'ê³¼ 'updates'ë¥¼ ì„ì–´ì„œ ë§ì´ ì”ë‹ˆë‹¤.
# stream_mode=["custom", "updates"]: 
#   1. "custom": ë…¸ë“œ ë‚´ë¶€ì—ì„œ writer()ë¥¼ í†µí•´ ë³´ë‚¸ ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©ì´ë‚˜ ì¤‘ê°„ ë°ì´í„°ë¥¼ ìˆ˜ì‹ 
#   2. "updates": ë…¸ë“œ ì‹¤í–‰ì´ ì™„ë£Œëœ í›„ ë°˜í™˜(return)ëœ ìƒíƒœ ì—…ë°ì´íŠ¸ ê°’ì„ ìˆ˜ì‹ 
for mode, chunk in app.stream(inputs, stream_mode=["custom", "updates"]):
    if mode == "custom":
        # writer("ë¬¸ìì—´")ë¡œ ë³´ë‚¸ ë‚´ìš©ì´ chunkì— ë“¤ì–´ì˜µë‹ˆë‹¤.
        print(f"[ì§„í–‰ ìƒí™©] {chunk}")
    elif mode == "updates":
        # ë…¸ë“œê°€ returní•œ ë”•ì…”ë„ˆë¦¬(ìƒíƒœ ë³€ê²½ë¶„)ê°€ chunkì— ë“¤ì–´ì˜µë‹ˆë‹¤.
        for node_name, output in chunk.items():
            print(f"[{node_name}] ë‹¨ê³„ ì™„ë£Œ: {output}")

# =========================================================
# 2. messages ìŠ¤íŠ¸ë¦¼ + metadata í•„í„°ë§ (ëˆ„ê°€ / ì–´ë””ì„œ ë§í–ˆëŠ”ì§€)
# =========================================================

"""
[ìš”ì•½ ì„¤ëª…]
ìœ„ ì½”ë“œëŠ” 'ë©”íƒ€ë°ì´í„°(Tag)'ë¥¼ í™œìš©í•´ ë©€í‹° LLM ìŠ¤íŠ¸ë¦¬ë°ì„ ì œì–´í•˜ëŠ” íŒ¨í„´ì…ë‹ˆë‹¤.
1. ëª¨ë¸ ì´ˆê¸°í™” ì‹œ(init_chat_model) `tags=["insight"]` ë“±ì„ ì„¤ì •í•´ë‘¡ë‹ˆë‹¤.
2. `stream_mode="messages"`ë¡œ ì‹¤í–‰í•˜ë©´, í† í°ê³¼ í•¨ê»˜ ë©”íƒ€ë°ì´í„°ê°€ ë„˜ì–´ì˜µë‹ˆë‹¤.
3. `if "insight" in metadata.get("tags", []):` ì¡°ê±´ë¬¸ìœ¼ë¡œ íƒœê·¸ë¥¼ í™•ì¸í•˜ì—¬,
   ë³‘ë ¬ë¡œ ì‹¤í–‰ë˜ëŠ” ì—¬ëŸ¬ ëª¨ë¸ ì¤‘ ì›í•˜ëŠ” ëª¨ë¸ì˜ ë‹µë³€ë§Œ ê³¨ë¼ì„œ ì¶œë ¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""

import asyncio
from typing import TypedDict
from langgraph.graph import START, StateGraph
from langchain.chat_models import init_chat_model

# 1. ì„œë¡œ ë‹¤ë¥¸ ì—­í• ì„ ê°€ì§„ ëª¨ë¸ ì„¤ì •
# í•˜ë‚˜ëŠ” 'technical' íƒœê·¸ë¥¼, í•˜ë‚˜ëŠ” 'insight' íƒœê·¸ë¥¼ ê°€ì§‘ë‹ˆë‹¤.
analysis_model = init_chat_model(model="claude-haiku-4-5-20251001", model_provider="anthropic", tags=["technical"])
insight_model = init_chat_model(model="claude-haiku-4-5-20251001", model_provider="anthropic", tags=["insight"])

class ReportState(TypedDict):
    topic: str
    data_summary: str
    key_insights: str

# 2. ë…¸ë“œ ì •ì˜
async def analyze_data(state: ReportState, config):
    # ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜
    res = await analysis_model.ainvoke(
        [{"role": "user", "content": f"{state['topic']}ì— ëŒ€í•œ ìˆ˜ì¹˜ì  í†µê³„ ì •ë³´ë¥¼ ìš”ì•½í•´ì¤˜"}],
        config
    )
    return {"data_summary": res.content}

async def generate_insights(state: ReportState, config):
    # í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ ì‹œë®¬ë ˆì´ì…˜
    # insight_modelì€ ì´ˆê¸°í™” ì‹œ tags=["insight"]ê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
    # ì´ íƒœê·¸ ë•ë¶„ì— ìŠ¤íŠ¸ë¦¬ë° ì‹œ ë©”íƒ€ë°ì´í„° í•„í„°ë§(metadata.get("tags"))ì„ í†µí•´
    # íŠ¹ì • ëª¨ë¸ì˜ ì¶œë ¥ë§Œ ì„ ë³„í•´ì„œ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    res = await insight_model.ainvoke(
        [{"role": "user", "content": f"{state['topic']}ì˜ í–¥í›„ ì „ë§ê³¼ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ë¥¼ ë§í•´ì¤˜"}],
        config
    )
    return {"key_insights": res.content}

# 3. ê·¸ë˜í”„ êµ¬ì„± (ë³‘ë ¬ ì²˜ë¦¬)
builder = StateGraph(ReportState)
builder.add_node("analyze", analyze_data)
builder.add_node("insight", generate_insights)

builder.add_edge(START, "analyze")
builder.add_edge(START, "insight")

report_app = builder.compile()

# 4. ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰ (ë©”íƒ€ë°ì´í„° í•„í„°ë§)
async def run_report_stream():
    print(f"--- 'ì „ê¸°ì°¨ ì‹œì¥' ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ (ì¸ì‚¬ì´íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ì¤‘) ---\n")
    
    inputs = {"topic": "2026ë…„ ì „ê¸°ì°¨ ì‹œì¥ ì „ë§"}
    
    async for msg, metadata in report_app.astream(
        inputs, 
        stream_mode="messages"
    ):
        # ë©”ì‹œì§€ ë‚´ìš©ì´ ì—†ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì´ë©´ ìŠ¤í‚µ
        if not msg.content:
            continue
            
        # [í•„í„°ë§] 'insight' íƒœê·¸ê°€ ë‹¬ë¦° ëª¨ë¸ì˜ ë‹µë³€ë§Œ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°
        if "insight" in metadata.get("tags", []):
            print(msg.content, end="", flush=True)
            
    print("\n\n--- ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ ---")

asyncio.run(run_report_stream())

# =========================================================
# 3. LangChainì„ ì•ˆ ì“°ëŠ” LLMì´ë¼ë„, í† í° ìŠ¤íŠ¸ë¦¬ë°ì„ custom ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ LangGraphì— ë¼ì›Œ ë„£ì„ ìˆ˜ ìˆìŒ
# =========================================================

"""
[ì´ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ ]
1. ìµœì‹  ê¸°ëŠ¥ í™œìš©: LangChainì—ì„œ ì•„ì§ ì§€ì›í•˜ì§€ ì•ŠëŠ” ê° LLM ëª¨ë¸ì˜ ìµœì‹  API ê¸°ëŠ¥ì„ ì§ì ‘ ì œì–´í•˜ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
2. ì™„ì „í•œ ì œì–´ê¶Œ: í† í°ë¿ë§Œ ì•„ë‹ˆë¼ ì¤‘ê°„ ì—°ì‚° ê³¼ì •, ë¡œê·¸, ì»¤ìŠ¤í…€ ì‹œê°í™” ë°ì´í„° ë“± 'ë‚´ê°€ ì›í•˜ëŠ” í¬ë§·'ì„ ì§ì ‘ ì •ì˜í•´ì„œ ìŠ¤íŠ¸ë¦¬ë° ì±„ë„ì— íƒœì›Œ ë³´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. ìœ ì—°í•œ í†µí•©: LangChainì˜ ì¶”ìƒí™” ê³„ì¸µ ì—†ì´ ìˆœìˆ˜ íŒŒì´ì¬ ë¡œì§ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©´ì„œë„, LangGraphì˜ ìƒíƒœ ê´€ë¦¬(State)ì™€ ì œì–´ íë¦„(Graph) ì•ˆì—ì„œ ì¡°í™”ë¡­ê²Œ ë™ì‘í•˜ë„ë¡ ì„¤ê³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
import asyncio
import json
import operator
from typing import TypedDict, Annotated
from typing_extensions import Annotated
from langgraph.graph import StateGraph, START
from langgraph.config import get_stream_writer
from anthropic import AsyncAnthropic

# 1. ì´ˆê¸° ì„¤ì •
client = AsyncAnthropic()
MODEL = "claude-haiku-4-5-20251001"

class State(TypedDict):
    # ë©”ì‹œì§€ ì´ë ¥ì„ ëˆ„ì í•˜ê¸° ìœ„í•œ ì„¤ì •
    messages: Annotated[list[dict], operator.add]

# 2. ë¡œìš° ë ˆë²¨ í† í° ìŠ¤íŠ¸ë¦¬ë¨¸
async def raw_llm_stream(prompt: str):
    response = await client.messages.create(
        messages=[{"role": "user", "content": prompt}],
        model=MODEL,
        max_tokens=1000,
        stream=True
    )
    async for chunk in response:
        if chunk.type == "content_block_delta" and chunk.delta.type == "text_delta":
            yield chunk.delta.text

# 3. Custom ìŠ¤íŠ¸ë¦¬ë°ì„ ì‚¬ìš©í•˜ëŠ” ë„êµ¬ (ì½”ë“œ ë¦¬ë·° ë„êµ¬)
async def review_code_tool(code_snippet: str) -> str:
    """ì½”ë“œë¥¼ ë¶„ì„í•˜ê³  ê°œì„ ì ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤."""
    writer = get_stream_writer()
    full_response = ""
    
    prompt = f"ë‹¤ìŒ ì½”ë“œì˜ ë²„ê·¸ë‚˜ ê°œì„ ì ì„ 3ê°€ì§€ë§Œ ì§€ì í•´ì¤˜:\n{code_snippet}"
    
    # ë„êµ¬ ë‚´ë¶€ì—ì„œ í† í°ë³„ë¡œ ìŠ¤íŠ¸ë¦¬ë° ë°œìƒ
    async for token in raw_llm_stream(prompt):
        full_response += token
        # custom ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ í† í° ì „ì†¡
        writer({"type": "token", "content": token})
    
    return full_response

# 4. ê·¸ë˜í”„ ë…¸ë“œ (ë„êµ¬ ì‹¤í–‰ ë¡œì§)
async def tool_node(state: State):
    last_msg = state["messages"][-1]
    t_call = last_msg["tool_calls"][0]
    
    args = json.loads(t_call["function"]["arguments"])
    
    # ë„êµ¬ ì‹¤í–‰ (ë‚´ë¶€ì—ì„œ writerë¥¼ í†µí•´ ìŠ¤íŠ¸ë¦¬ë° ì¨)
    result = await review_code_tool(args["code_snippet"])
    
    return {
        "messages": [{
            "tool_call_id": t_call["id"],
            "role": "tool",
            "name": "review_code_tool",
            "content": result
        }]
    }

# 5. ê·¸ë˜í”„ ë¹Œë“œ
builder = StateGraph(State)
builder.add_node("call_tool", tool_node)
builder.add_edge(START, "call_tool")
review_app = builder.compile()

# 6. ì‹¤í–‰ ë° custom ìŠ¤íŠ¸ë¦¼ ìˆ˜ì‹ 
async def run_review():
    print("--- ì‹¤ì‹œê°„ ì½”ë“œ ë¦¬ë·° ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ---")
    
    initial_input = {
        "messages": [{
            "role": "assistant",
            "content": None,
            "tool_calls": [{
                "id": "review_123",
                "function": {
                    "name": "review_code_tool",
                    "arguments": '{"code_snippet": "def add(a, b): return a+b"}'
                },
                "type": "function"
            }]
        }]
    }

    async for chunk in review_app.astream(initial_input, stream_mode="custom"):
        # chunkëŠ” ìœ„ì—ì„œ writer()ì— ë„£ì€ ë°ì´í„° í¬ë§· ê·¸ëŒ€ë¡œ ë‚˜ì˜µ/ë‹ˆë‹¤.
        if chunk.get("type") == "token":
            print(chunk["content"], end="", flush=True)

    print("\n--- ë¦¬ë·° ì™„ë£Œ ---")

if __name__ == "__main__":
    asyncio.run(run_review())

# =========================================================
# 4. Subgraph ìŠ¤íŠ¸ë¦¬ë°
# =========================================================
from langgraph.graph import START, END, StateGraph
from typing import TypedDict

# --- 1. í•˜ìœ„ ê·¸ë˜í”„ (ì¹´í”¼ ì œì‘ íŒ€) ---
class CopywritingState(TypedDict):
    base_idea: str  # ë¶€ëª¨ë¡œë¶€í„° ë°›ì„ í‚¤
    draft: str
    is_approved: bool

def write_draft_node(state: CopywritingState):
    print("  [ìì‹] ì´ˆì•ˆ ì‘ì„± ì¤‘...")
    return {"draft": f"ë©‹ì§„ ê´‘ê³  ë¬¸êµ¬: {state['base_idea']}!"}

def review_copy_node(state: CopywritingState):
    print("  [ìì‹] ê²€ìˆ˜ ì¤‘...")
    return {"is_approved": True}

sub_builder = StateGraph(CopywritingState)
sub_builder.add_node("writer", write_draft_node)
sub_builder.add_node("reviewer", review_copy_node)
sub_builder.add_edge(START, "writer")
sub_builder.add_edge("writer", "reviewer")
sub_builder.add_edge("reviewer", END)
copy_subgraph = sub_builder.compile()


# --- 2. ë¶€ëª¨ ê·¸ë˜í”„ (ë§ˆì¼€íŒ… ì „ëµ íŒ€) ---
class MarketingState(TypedDict):
    base_idea: str
    final_report: str

def planning_node(state: MarketingState):
    print("[ë¶€ëª¨] ì „ëµ ê¸°íš ì¤‘...")
    return {"base_idea": "ì¹œí™˜ê²½ í…€ë¸”ëŸ¬"}

def final_step_node(state: MarketingState):
    print("[ë¶€ëª¨] ìµœì¢… ë³´ê³ ì„œ ì •ë¦¬ ì¤‘...")
    return {"final_report": "ìº í˜ì¸ ì¤€ë¹„ ì™„ë£Œ"}

parent_builder = StateGraph(MarketingState)
parent_builder.add_node("planner", planning_node)
# í•˜ìœ„ ê·¸ë˜í”„ë¥¼ 'creative_team'ì´ë¼ëŠ” ì´ë¦„ì˜ ë…¸ë“œë¡œ ì¶”ê°€
parent_builder.add_node("creative_team", copy_subgraph)
parent_builder.add_node("reporter", final_step_node)

parent_builder.add_edge(START, "planner")
parent_builder.add_edge("planner", "creative_team")
parent_builder.add_edge("creative_team", "reporter")
parent_builder.add_edge("reporter", END)

marketing_app = parent_builder.compile()

# --- 3. ì‹¤í–‰ ë° ì„œë¸Œê·¸ë˜í”„ ìŠ¤íŠ¸ë¦¬ë° ê´€ì°° ---
print("### ë§ˆì¼€íŒ… í”„ë¡œì„¸ìŠ¤ ì‹œì‘ ###\n")

# subgraphs=True ì˜µì…˜ìœ¼ë¡œ ë‚´ë¶€ ì§„í–‰ìƒí™©ì„ íˆ¬ëª…í•˜ê²Œ í™•ì¸
for path, chunk in marketing_app.stream(
    {"base_idea": "ê¸°ë³¸ ì•„ì´ë””ì–´"}, 
    stream_mode="updates", 
    subgraphs=True
):
    # pathëŠ” í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ë…¸ë“œì˜ ìœ„ì¹˜ë¥¼ íŠœí”Œë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤. (ì˜ˆ: ('creative_team', 'writer'))
    if not path:
        node_name = "Root"
    else:
        node_name = path[-1]
    print(f"ê²½ë¡œ: {path} | ë…¸ë“œ: {node_name} | ì—…ë°ì´íŠ¸: {chunk}")

"""
[ì„œë¸Œê·¸ë˜í”„(Subgraph) ìš”ì•½ ì •ë¦¬]
1. ì •ì˜: ë…ë¦½ëœ ê·¸ë˜í”„ë¥¼ ë‹¤ë¥¸ ë¶€ëª¨ ê·¸ë˜í”„ì˜ 'í•˜ë‚˜ì˜ ë…¸ë“œ'ë¡œ í¬í•¨ì‹œí‚¨ êµ¬ì¡°ì…ë‹ˆë‹¤.
2. íŠ¹ì§•:
   - ìƒíƒœ ë¶„ë¦¬: ìì‹ ê·¸ë˜í”„ë§Œì˜ ì „ìš© ì¥ë¶€(State)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶€ëª¨ì˜ ë³µì¡ë„ë¥¼ ë‚®ì¶¥ë‹ˆë‹¤.
   - ëª¨ë“ˆí™”: íŠ¹ì • ê¸°ëŠ¥(ì˜ˆ: ì¹´í”¼ ì œì‘)ì„ ë…ë¦½ëœ ë¶€í’ˆì²˜ëŸ¼ ë§Œë“¤ì–´ ì—¬ëŸ¬ ê³³ì—ì„œ ì¬ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
   - ê´€ì°° ê°€ëŠ¥ì„±: stream(subgraphs=True) ì˜µì…˜ì„ í†µí•´ ë¸”ë™ë°•ìŠ¤ ê°™ë˜ ë‚´ë¶€ ì‹¤í–‰ ê³¼ì •ì„ íˆ¬ëª…í•˜ê²Œ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
3. ê²½ë¡œ(Path): íŠœí”Œ í˜•íƒœì˜ pathë¥¼ í†µí•´ í˜„ì¬ ì‘ì—…ì´ ë¶€ëª¨ ë…¸ë“œì¸ì§€ í˜¹ì€ íŠ¹ì • ì„¸ë¶€ ì—…ë¬´(ìì‹) ë‚´ë¶€ì¸ì§€ ê³„ì¸µì ìœ¼ë¡œ íŒŒì•…í•©ë‹ˆë‹¤.
"""

